{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cc55e3b",
   "metadata": {},
   "source": [
    "# TITIM Complete Experiment Notebook\n",
    "\n",
    "**Based on README.md and all script files â€” Generated for Jupyter Notebook implementation**\n",
    "\n",
    "---\n",
    "\n",
    "## TITIM: Training-Inference Trigger Intensity Mismatch in Backdoor Attacks\n",
    "\n",
    "**USENIX Security '25 Paper Implementation**\n",
    "\n",
    "This notebook implements the complete TITIM experiment pipeline based on the paper **\"Revisiting Training-Inference Trigger Intensity in Backdoor Attacks\"**.\n",
    "\n",
    "### ğŸ¯ Research Question\n",
    "**How does the mismatch between training and inference trigger intensities affect backdoor attack effectiveness?**\n",
    "\n",
    "### ğŸ“‹ Experiment Pipeline\n",
    "1. **Environment Setup** â€” Install dependencies and check hardware  \n",
    "2. **Dataset Preparation** â€” Download clean datasets (CIFAR-10, MNIST, GTSRB)  \n",
    "3. **Poisoned Data Generation** â€” Create datasets with varying trigger intensities (0.1â€“1.0)  \n",
    "4. **Model Training** â€” Train ResNet18 models on different intensity datasets  \n",
    "5. **Cross-Intensity Testing** â€” Test models on different intensity datasets (10Ã—10 matrix)  \n",
    "6. **Visualization & Analysis** â€” Generate heatmaps and analyze results  \n",
    "7. **Defense Evaluation** â€” Test ABL, Neural Cleanse, STRIP, etc.  \n",
    "8. **Mixed Intensity Experiments** â€” Advanced experiments with mixed intensities\n",
    "\n",
    "### ğŸ”§ Hardware Requirements\n",
    "- **Minimum**: 8GB RAM, 2GB NVIDIA GPU (for ResNet18 on CIFAR-10)  \n",
    "- **Recommended**: 128GB RAM, 24GB NVIDIA GPU (for full experiments)  \n",
    "- **OS**: Linux recommended (Ubuntu 22.04.4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16042a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 2: Environment Setup and Dependencies ===\n",
    "# Import libraries and setup environment\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML\n",
    "import warnings\n",
    "import time\n",
    "from datetime import datetime\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Change to TITIM-main directory\n",
    "os.chdir('TITIM-main')\n",
    "print(\"ğŸ“‚ Current working directory:\", os.getcwd())\n",
    "\n",
    "# Check Python version\n",
    "print(\"ğŸ Python version:\", sys.version)\n",
    "\n",
    "# Check GPU availability\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"ğŸ”¥ PyTorch version: {torch.__version__}\")\n",
    "    print(f\"ğŸ® CUDA available: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"ğŸ¯ GPU count: {torch.cuda.device_count()}\")\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            print(f\"   GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "    else:\n",
    "        print(\"âš ï¸  No GPU detected - CPU only mode\")\n",
    "except ImportError:\n",
    "    print(\"âŒ PyTorch not installed\")\n",
    "\n",
    "# Define helper function\n",
    "def run_command(cmd, show_output=True, background=False):\n",
    "    \"\"\"Execute shell command and return result\"\"\"\n",
    "    print(f\"âš¡ Executing: {cmd}\")\n",
    "    if background:\n",
    "        subprocess.Popen(cmd, shell=True)\n",
    "        return None\n",
    "    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)\n",
    "    if show_output and result.stdout:\n",
    "        print(\"ğŸ“¤ Output:\", result.stdout.strip())\n",
    "    if result.stderr and result.returncode != 0:\n",
    "        print(\"âŒ Error:\", result.stderr.strip())\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ff7712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 3: Dependency Check ===\n",
    "print(\"ğŸ” Checking dependencies...\")\n",
    "\n",
    "required_packages = [\n",
    "    'torch', 'torchvision', 'numpy', 'pandas', 'matplotlib', \n",
    "    'sklearn', 'cv2', 'seaborn', 'tqdm', 'PIL'\n",
    "]\n",
    "\n",
    "missing_packages = []\n",
    "for package in required_packages:\n",
    "    try:\n",
    "        if package == 'cv2':\n",
    "            import cv2\n",
    "        elif package == 'sklearn':\n",
    "            import sklearn\n",
    "        elif package == 'PIL':\n",
    "            from PIL import Image\n",
    "        else:\n",
    "            __import__(package)\n",
    "        print(f\"âœ… {package}: Installed\")\n",
    "    except ImportError:\n",
    "        print(f\"âŒ {package}: Missing\")\n",
    "        missing_packages.append(package)\n",
    "\n",
    "if missing_packages:\n",
    "    print(f\"\\nâš ï¸  Missing packages: {missing_packages}\")\n",
    "    print(\"Please run: pip install -r requirements.txt\")\n",
    "else:\n",
    "    print(\"\\nğŸ‰ All dependencies satisfied!\")\n",
    "\n",
    "# Check if we're in virtual environment\n",
    "if 'titim' in sys.executable.lower():\n",
    "    print(\"ğŸŒ Running in TITIM virtual environment\")\n",
    "else:\n",
    "    print(\"âš ï¸  Not in virtual environment - consider using one\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fd89ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 4: Dataset Preparation ===\n",
    "# Download clean datasets following scripts/get_clean_datasets.sh\n",
    "print(\"ğŸ“¦ Downloading clean datasets...\")\n",
    "\n",
    "datasets = ['cifar10', 'mnist', 'gtsrb']  # Excluding celeba8 for faster execution\n",
    "success_count = 0\n",
    "\n",
    "for dataset in datasets:\n",
    "    print(f\"\\nğŸ“¥ Getting {dataset.upper()} dataset...\")\n",
    "    cmd = f\"python utils/scripts/dataset_get_clean.py --dataset {dataset}\"\n",
    "    result = run_command(cmd, show_output=False)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(f\"âœ… {dataset.upper()} downloaded successfully\")\n",
    "        success_count += 1\n",
    "    else:\n",
    "        print(f\"âŒ {dataset.upper()} download failed\")\n",
    "        if result.stderr:\n",
    "            print(f\"Error: {result.stderr}\")\n",
    "\n",
    "print(f\"\\nğŸ“Š Dataset download summary: {success_count}/{len(datasets)} successful\")\n",
    "\n",
    "# Verify dataset structure\n",
    "print(\"\\nğŸ” Verifying dataset structure...\")\n",
    "data_dir = \"data\"\n",
    "if os.path.exists(data_dir):\n",
    "    for dataset in datasets:\n",
    "        dataset_path = os.path.join(data_dir, dataset, \"clean\")\n",
    "        if os.path.exists(dataset_path):\n",
    "            files = os.listdir(dataset_path)\n",
    "            print(f\"âœ… {dataset}: {files}\")\n",
    "        else:\n",
    "            print(f\"âŒ {dataset}: Directory not found\")\n",
    "else:\n",
    "    print(\"âŒ Data directory not found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47796122",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 5: Poisoned Dataset Generation ===\n",
    "# Generate poisoned datasets with varying trigger intensities\n",
    "# Following scripts/inject/inject_badnets_square.sh\n",
    "\n",
    "print(\"ğŸ¦  Generating poisoned datasets with BadNets (Square) attack...\")\n",
    "\n",
    "# Experiment parameters\n",
    "dataset = 'cifar10'  # Focus on CIFAR-10 for main experiment\n",
    "target = 0\n",
    "trigger = 'badnets'\n",
    "ratio = 0.05  # 5% poisoning ratio\n",
    "intensities = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "\n",
    "print(f\"ğŸ¯ Target class: {target}\")\n",
    "print(f\"ğŸ¦  Poisoning ratio: {ratio}\")\n",
    "print(f\"ğŸ›ï¸  Trigger intensities: {intensities}\")\n",
    "print(f\"ğŸ”² Trigger type: {trigger} (4x4 square)\")\n",
    "\n",
    "# Generate datasets for each intensity\n",
    "success_count = 0\n",
    "start_time = time.time()\n",
    "\n",
    "for i, mr in enumerate(intensities):\n",
    "    print(f\"\\n[{i+1}/{len(intensities)}] ğŸ›ï¸  Generating intensity {mr} dataset...\")\n",
    "    \n",
    "    cmd = (f\"python inject.py --dataset {dataset} --target {target} \"\n",
    "           f\"--ratio {ratio} --trigger {trigger} --mr {mr} \"\n",
    "           f\"--block_size 4 --fixed --split_val test\")\n",
    "    \n",
    "    result = run_command(cmd, show_output=False)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(f\"âœ… Intensity {mr}: SUCCESS\")\n",
    "        success_count += 1\n",
    "    else:\n",
    "        print(f\"âŒ Intensity {mr}: FAILED\")\n",
    "        if result.stderr:\n",
    "            print(f\"   Error: {result.stderr[:200]}...\")\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"\\nâ±ï¸  Generation completed in {elapsed_time:.1f}s\")\n",
    "print(f\"ğŸ“Š Success rate: {success_count}/{len(intensities)} ({100*success_count/len(intensities):.1f}%)\")\n",
    "\n",
    "# Verify generated datasets\n",
    "print(\"\\nğŸ” Verifying generated datasets...\")\n",
    "poisoned_datasets = []\n",
    "data_dir = f\"data/{dataset}\"\n",
    "if os.path.exists(data_dir):\n",
    "    for item in os.listdir(data_dir):\n",
    "        if item.startswith('badnets_b4_bn3_ppt1_mr'):\n",
    "            poisoned_datasets.append(item)\n",
    "            dataset_path = os.path.join(data_dir, item)\n",
    "            files = os.listdir(dataset_path)\n",
    "            print(f\"âœ… {item}: {len(files)} files\")\n",
    "\n",
    "print(f\"\\nğŸ“ˆ Total poisoned datasets: {len(poisoned_datasets)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c90504b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 6: Backdoor Model Training ===\n",
    "# Train backdoor models following scripts/train/train_badnets_square.sh\n",
    "print(\"ğŸ“ Training backdoor models...\")\n",
    "\n",
    "# Training parameters\n",
    "model = 'resnet18'\n",
    "epochs = 100\n",
    "batch_size = 128\n",
    "learning_rate = 1e-2\n",
    "optimizer = 'adam'\n",
    "gpu = 0\n",
    "\n",
    "print(f\"ğŸ—ï¸  Model architecture: {model}\")\n",
    "print(f\"ğŸ”„ Training epochs: {epochs}\")\n",
    "print(f\"ğŸ“¦ Batch size: {batch_size}\")\n",
    "print(f\"ğŸ“ˆ Learning rate: {learning_rate}\")\n",
    "print(f\"âš™ï¸  Optimizer: {optimizer}\")\n",
    "\n",
    "# Create logs directory\n",
    "os.makedirs(\"logs\", exist_ok=True)\n",
    "log_file = \"logs/badnets.tsv\"\n",
    "\n",
    "# Train models for each intensity\n",
    "success_count = 0\n",
    "start_time = time.time()\n",
    "\n",
    "for i, mr in enumerate(intensities):\n",
    "    print(f\"\\n[{i+1}/{len(intensities)}] ğŸ“ Training model for intensity {mr}...\")\n",
    "    \n",
    "    subset = f\"badnets_b4_bn3_ppt1_mr{mr}_{ratio}\"\n",
    "    cmd = (f\"python train.py --gpu {gpu} --model {model} --dataset {dataset} \"\n",
    "           f\"--subset {subset} --epochs {epochs} --bs {batch_size} \"\n",
    "           f\"--lr {learning_rate} --optimizer {optimizer} --log {log_file} \"\n",
    "           f\"--mode cover --split_val test --disable_prog\")\n",
    "    \n",
    "    model_start = time.time()\n",
    "    result = run_command(cmd, show_output=False)\n",
    "    model_time = time.time() - model_start\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(f\"âœ… Intensity {mr}: SUCCESS ({model_time:.1f}s)\")\n",
    "        success_count += 1\n",
    "    else:\n",
    "        print(f\"âŒ Intensity {mr}: FAILED\")\n",
    "        if result.stderr:\n",
    "            print(f\"   Error: {result.stderr[:200]}...\")\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\nâ±ï¸  Training completed in {total_time:.1f}s ({total_time/60:.1f} minutes)\")\n",
    "print(f\"ğŸ“Š Success rate: {success_count}/{len(intensities)} ({100*success_count/len(intensities):.1f}%)\")\n",
    "\n",
    "# Verify trained models\n",
    "print(\"\\nğŸ” Verifying trained models...\")\n",
    "trained_models = []\n",
    "res_dir = \"res\"\n",
    "if os.path.exists(res_dir):\n",
    "    for item in os.listdir(res_dir):\n",
    "        if 'resnet18' in item and 'badnets' in item:\n",
    "            trained_models.append(item)\n",
    "            model_path = os.path.join(res_dir, item)\n",
    "            files = os.listdir(model_path)\n",
    "            print(f\"âœ… {item}: {len(files)} files\")\n",
    "\n",
    "print(f\"\\nğŸ“ˆ Total trained models: {len(trained_models)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faab1d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 7: Cross-Intensity Testing (Core Experiment) ===\n",
    "# Cross-intensity testing following scripts/inference/crosstest_badnets_square.sh\n",
    "print(\"ğŸ¯ Starting cross-intensity testing (CORE EXPERIMENT)...\")\n",
    "print(\"This tests how models trained on one intensity perform on different intensities.\")\n",
    "\n",
    "# Setup test log file\n",
    "test_log_file = \"logs/cross_badnets_square.tsv\"\n",
    "os.makedirs(\"logs\", exist_ok=True)\n",
    "\n",
    "# Initialize log file with header\n",
    "with open(test_log_file, 'w') as f:\n",
    "    f.write(\"name\\tasr\\n\")\n",
    "\n",
    "print(f\"ğŸ“ Results will be saved to: {test_log_file}\")\n",
    "\n",
    "# Calculate total number of tests\n",
    "total_tests = len(intensities) * len(intensities)\n",
    "print(f\"ğŸ“Š Total tests to perform: {total_tests} (10x10 matrix)\")\n",
    "\n",
    "# Perform cross-intensity testing\n",
    "success_count = 0\n",
    "current_test = 0\n",
    "start_time = time.time()\n",
    "\n",
    "for train_mr in intensities:\n",
    "    for test_mr in intensities:\n",
    "        current_test += 1\n",
    "        print(f\"\\n[{current_test}/{total_tests}] ğŸ¯ Testing: Train={train_mr}, Test={test_mr}\")\n",
    "        \n",
    "        # Construct paths and names\n",
    "        model_dir = f\"{model}_{dataset}_badnets_b4_bn3_ppt1_mr{train_mr}_{ratio}_e{epochs}\"\n",
    "        test_subset = f\"badnets_b4_bn3_ppt1_mr{test_mr}_{ratio}\"\n",
    "        test_name = f\"{model}_{dataset}_badnets_b4_bn3_ppt1_mr{train_mr}_{ratio}_e{epochs}_tmr{test_mr}\"\n",
    "        \n",
    "        cmd = (f\"python evaluate.py --gpu {gpu} --model_dir {model_dir} \"\n",
    "               f\"--dataset {dataset} --subset {test_subset} --split test \"\n",
    "               f\"--log {test_log_file} --name {test_name}\")\n",
    "        \n",
    "        result = run_command(cmd, show_output=False)\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(f\"âœ… SUCCESS\")\n",
    "            success_count += 1\n",
    "        else:\n",
    "            print(f\"âŒ FAILED\")\n",
    "            if result.stderr:\n",
    "                print(f\"   Error: {result.stderr[:100]}...\")\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print(f\"\\nâ±ï¸  Cross-intensity testing completed in {elapsed_time:.1f}s ({elapsed_time/60:.1f} minutes)\")\n",
    "print(f\"ğŸ“Š Success rate: {success_count}/{total_tests} ({100*success_count/total_tests:.1f}%)\")\n",
    "\n",
    "# Load and preview results\n",
    "if os.path.exists(test_log_file):\n",
    "    print(f\"\\nğŸ“ˆ Loading results from {test_log_file}...\")\n",
    "    results_df = pd.read_csv(test_log_file, sep='\\t')\n",
    "    print(f\"ğŸ“Š Total results: {len(results_df)}\")\n",
    "    \n",
    "    if len(results_df) > 0:\n",
    "        print(\"\\nğŸ” Preview of results:\")\n",
    "        display(results_df.head(10))\n",
    "        \n",
    "        # Basic statistics\n",
    "        asr_values = pd.to_numeric(results_df['asr'], errors='coerce')\n",
    "        print(f\"\\nğŸ“Š ASR Statistics:\")\n",
    "        print(f\"   ğŸ“ˆ Max ASR: {asr_values.max():.3f}\")\n",
    "        print(f\"   ğŸ“‰ Min ASR: {asr_values.min():.3f}\")\n",
    "        print(f\"   ğŸ“Š Mean ASR: {asr_values.mean():.3f}\")\n",
    "        print(f\"   ğŸ“ Std ASR: {asr_values.std():.3f}\")\n",
    "else:\n",
    "    print(\"âŒ Results file not found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9434f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 8: Results Visualization & Analysis ===\n",
    "# Generate official heatmap using utils/scripts/draw_heatmap.py\n",
    "print(\"ğŸ“Š Generating visualization and analysis...\")\n",
    "\n",
    "# Use official heatmap script\n",
    "heatmap_name = \"resnet18_cifar10_badnets_b4_bn3_ppt1_mrx_0.05\"\n",
    "heatmap_cmd = f\"python utils/scripts/draw_heatmap.py --name {heatmap_name} --N 10\"\n",
    "print(f\"ğŸ¨ Generating official heatmap: {heatmap_name}\")\n",
    "\n",
    "result = run_command(heatmap_cmd, show_output=False)\n",
    "if result.returncode == 0:\n",
    "    print(\"âœ… Official heatmap generated successfully\")\n",
    "else:\n",
    "    print(\"âŒ Official heatmap generation failed\")\n",
    "    if result.stderr:\n",
    "        print(f\"Error: {result.stderr}\")\n",
    "\n",
    "# Check generated files\n",
    "heatmap_dir = \"heatmaps\"\n",
    "if os.path.exists(heatmap_dir):\n",
    "    files = os.listdir(heatmap_dir)\n",
    "    print(f\"ğŸ“ Generated heatmap files: {files}\")\n",
    "else:\n",
    "    print(\"ğŸ“ Heatmap directory not found\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8273ba81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 9: Custom Analysis and Visualization ===\n",
    "# Custom analysis and visualization\n",
    "if os.path.exists(test_log_file):\n",
    "    print(\"ğŸ”¬ Performing custom analysis...\")\n",
    "    \n",
    "    # Load results\n",
    "    results_df = pd.read_csv(test_log_file, sep='\\t')\n",
    "    \n",
    "    # Extract training and testing intensities\n",
    "    results_df['train_mr'] = results_df['name'].str.extract(r'mr(\\d+\\.\\d+)_0\\.05_e100_tmr')\n",
    "    results_df['test_mr'] = results_df['name'].str.extract(r'tmr(\\d+\\.\\d+)')\n",
    "    \n",
    "    # Convert to numeric\n",
    "    results_df['train_mr'] = pd.to_numeric(results_df['train_mr'])\n",
    "    results_df['test_mr'] = pd.to_numeric(results_df['test_mr'])\n",
    "    results_df['asr'] = pd.to_numeric(results_df['asr'], errors='coerce')\n",
    "    \n",
    "    # Create pivot table for heatmap\n",
    "    pivot_table = results_df.pivot(index='train_mr', columns='test_mr', values='asr')\n",
    "    \n",
    "    # Generate custom heatmap\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(pivot_table, annot=True, fmt='.3f', cmap='YlOrRd', \n",
    "                cbar_kws={'label': 'Attack Success Rate (ASR)'},\n",
    "                square=True, linewidths=0.5)\n",
    "    plt.title('TITIM: Cross-Intensity Attack Success Rate\\n(Training Intensity vs Testing Intensity)', \n",
    "              fontsize=16, fontweight='bold')\n",
    "    plt.xlabel('Test Trigger Intensity', fontsize=14)\n",
    "    plt.ylabel('Training Trigger Intensity', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Diagonal analysis (Training = Testing intensity)\n",
    "    diagonal_asr = []\n",
    "    for mr in intensities:\n",
    "        if mr in pivot_table.index and mr in pivot_table.columns:\n",
    "            diagonal_asr.append(pivot_table.loc[mr, mr])\n",
    "        else:\n",
    "            diagonal_asr.append(np.nan)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(intensities, diagonal_asr, 'bo-', linewidth=3, markersize=10, label='Matched Intensity')\n",
    "    plt.xlabel('Trigger Intensity (Training = Testing)', fontsize=12)\n",
    "    plt.ylabel('Attack Success Rate', fontsize=12)\n",
    "    plt.title('ASR vs Trigger Intensity (Matched Training-Testing)', fontsize=14, fontweight='bold')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"\\nğŸ” Diagonal Analysis (Training = Testing intensity):\")\n",
    "    for i, mr in enumerate(intensities):\n",
    "        if not np.isnan(diagonal_asr[i]):\n",
    "            print(f\"   Intensity {mr}: ASR = {diagonal_asr[i]:.3f}\")\n",
    "    \n",
    "    # Mismatch analysis\n",
    "    results_df['intensity_mismatch'] = abs(results_df['train_mr'] - results_df['test_mr'])\n",
    "    mismatch_corr = results_df['intensity_mismatch'].corr(results_df['asr'])\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Key Findings:\")\n",
    "    print(f\"   ğŸ”— Intensity mismatch vs ASR correlation: {mismatch_corr:.3f}\")\n",
    "    \n",
    "    # Best and worst cases\n",
    "    max_idx = results_df['asr'].idxmax()\n",
    "    min_idx = results_df['asr'].idxmin()\n",
    "    best_case = results_df.loc[max_idx]\n",
    "    worst_case = results_df.loc[min_idx]\n",
    "    \n",
    "    print(f\"   ğŸ† Highest ASR: {best_case['asr']:.3f} (Train: {best_case['train_mr']}, Test: {best_case['test_mr']})\")\n",
    "    print(f\"   ğŸ“‰ Lowest ASR: {worst_case['asr']:.3f} (Train: {worst_case['train_mr']}, Test: {worst_case['test_mr']})\")\n",
    "    \n",
    "else:\n",
    "    print(\"âŒ No results file found for analysis\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929a4bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 10: Defense Evaluation ===\n",
    "# Test defense methods following scripts/defenses/\n",
    "print(\"ğŸ›¡ï¸  Testing backdoor defense methods...\")\n",
    "\n",
    "defense_methods = {\n",
    "    'abl': 'Activation-based Backdoor Learning',\n",
    "    'nc': 'Neural Cleanse', \n",
    "    'strip': 'STRIP',\n",
    "    'ss': 'Spectral Signature'\n",
    "}\n",
    "\n",
    "print(\"Available defense methods:\")\n",
    "for method, description in defense_methods.items():\n",
    "    print(f\"   ğŸ›¡ï¸  {method.upper()}: {description}\")\n",
    "\n",
    "# Test Neural Cleanse (fastest to demonstrate)\n",
    "print(f\"\\nğŸ§ª Testing Neural Cleanse defense...\")\n",
    "defense_cmd = f\"bash scripts/defenses/defense_nc.sh {gpu} {dataset} {model}\"\n",
    "result = run_command(defense_cmd, show_output=False)\n",
    "\n",
    "if result.returncode == 0:\n",
    "    print(\"âœ… Neural Cleanse defense test completed\")\n",
    "else:\n",
    "    print(\"âŒ Neural Cleanse defense test failed\")\n",
    "    if result.stderr:\n",
    "        print(f\"Error: {result.stderr[:200]}...\")\n",
    "\n",
    "# Check defense results\n",
    "defense_log = \"logs/defense_nc.csv\"\n",
    "if os.path.exists(defense_log):\n",
    "    print(f\"\\nğŸ“Š Defense results saved to: {defense_log}\")\n",
    "    try:\n",
    "        defense_results = pd.read_csv(defense_log)\n",
    "        print(f\"ğŸ“ˆ Defense test results: {len(defense_results)} entries\")\n",
    "        if len(defense_results) > 0:\n",
    "            display(defense_results.head())\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading defense results: {e}\")\n",
    "else:\n",
    "    print(\"âŒ Defense results file not found\")\n",
    "\n",
    "print(\"\\nğŸ’¡ To test other defenses, run the corresponding scripts:\")\n",
    "print(\"   bash scripts/defenses/defense_abl.sh 0 cifar10 resnet18\")\n",
    "print(\"   bash scripts/defenses/defense_strip.sh 0 cifar10 resnet18\")\n",
    "print(\"   bash scripts/defenses/defense_ss.sh 0 cifar10 resnet18\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a9ec6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 11: Mixed Intensity Experiments ===\n",
    "# Mixed intensity experiments following scripts/mixtest/\n",
    "print(\"ğŸ­ Running mixed intensity experiments...\")\n",
    "print(\"This tests models trained with mixed trigger intensities.\")\n",
    "\n",
    "# Mixed intensity parameters\n",
    "mixmr = 0.1  # Base intensity for mixing\n",
    "print(f\"ğŸ›ï¸  Base mixing intensity: {mixmr}\")\n",
    "\n",
    "# Run mixed intensity scripts\n",
    "mix_scripts = [\n",
    "    (\"inject_mix.sh\", \"Generate mixed intensity datasets\"),\n",
    "    (\"train_mix.sh\", \"Train mixed intensity models\"),\n",
    "    (\"crosstest_mix.sh\", \"Cross-test mixed models\"),\n",
    "    (\"draw_mix.sh\", \"Generate mixed intensity heatmap\")\n",
    "]\n",
    "\n",
    "for i, (script, description) in enumerate(mix_scripts):\n",
    "    print(f\"\\n[{i+1}/{len(mix_scripts)}] ğŸ­ {description}...\")\n",
    "    \n",
    "    if script == \"train_mix.sh\":\n",
    "        cmd = f\"bash scripts/mixtest/{script} {gpu} {dataset} {model} {ratio} {mixmr}\"\n",
    "    elif script == \"crosstest_mix.sh\":\n",
    "        cmd = f\"bash scripts/mixtest/{script} {gpu} {dataset} {model} {ratio} {mixmr}\"\n",
    "    else:\n",
    "        cmd = f\"bash scripts/mixtest/{script}\"\n",
    "    \n",
    "    result = run_command(cmd, show_output=False)\n",
    "    \n",
    "    if result.returncode == 0:\n",
    "        print(f\"âœ… {script}: SUCCESS\")\n",
    "    else:\n",
    "        print(f\"âŒ {script}: FAILED\")\n",
    "        if result.stderr:\n",
    "            print(f\"   Error: {result.stderr[:200]}...\")\n",
    "\n",
    "# Check mixed intensity results\n",
    "mix_log_file = f\"logs/cross_badnets_mixmr{mixmr}_{ratio}_{model}.tsv\"\n",
    "if os.path.exists(mix_log_file):\n",
    "    print(f\"\\nğŸ“Š Mixed intensity results: {mix_log_file}\")\n",
    "    mix_results = pd.read_csv(mix_log_file, sep='\\t')\n",
    "    print(f\"ğŸ“ˆ Mixed intensity test results: {len(mix_results)} entries\")\n",
    "    if len(mix_results) > 0:\n",
    "        display(mix_results.head())\n",
    "else:\n",
    "    print(f\"âŒ Mixed intensity results not found: {mix_log_file}\")\n",
    "\n",
    "# Check for mixed intensity heatmap\n",
    "mix_heatmap = f\"heatmaps/cross_badnets_mixmr{mixmr}_{ratio}_{model}.pdf\"\n",
    "if os.path.exists(mix_heatmap):\n",
    "    print(f\"âœ… Mixed intensity heatmap generated: {mix_heatmap}\")\n",
    "else:\n",
    "    print(f\"âŒ Mixed intensity heatmap not found: {mix_heatmap}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c7d710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CELL 12: Experiment Summary & Final Analysis ===\n",
    "# Comprehensive experiment summary\n",
    "print(\"ğŸ“‹ TITIM EXPERIMENT SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Check completion status\n",
    "experiment_stages = {\n",
    "    \"ğŸ“¦ Dataset Preparation\": os.path.exists(\"data/cifar10/clean\"),\n",
    "    \"ğŸ¦  Poisoned Data Generation\": len([d for d in os.listdir(\"data/cifar10\") if d.startswith('badnets')]) >= 5 if os.path.exists(\"data/cifar10\") else False,\n",
    "    \"ğŸ“ Model Training\": len([d for d in os.listdir(\"res\") if 'resnet18' in d and 'badnets' in d]) >= 5 if os.path.exists(\"res\") else False,\n",
    "    \"ğŸ¯ Cross-Intensity Testing\": os.path.exists(\"logs/cross_badnets_square.tsv\"),\n",
    "    \"ğŸ“Š Visualization\": os.path.exists(\"heatmaps\") and len(os.listdir(\"heatmaps\")) > 0 if os.path.exists(\"heatmaps\") else False,\n",
    "    \"ğŸ›¡ï¸  Defense Evaluation\": os.path.exists(\"logs/defense_nc.csv\"),\n",
    "    \"ğŸ­ Mixed Intensity Tests\": os.path.exists(f\"logs/cross_badnets_mixmr{mixmr}_{ratio}_{model}.tsv\")\n",
    "}\n",
    "\n",
    "print(\"\\nğŸ Experiment Completion Status:\")\n",
    "completed_stages = 0\n",
    "for stage, status in experiment_stages.items():\n",
    "    status_icon = \"âœ…\" if status else \"âŒ\"\n",
    "    print(f\"   {status_icon} {stage}\")\n",
    "    if status:\n",
    "        completed_stages += 1\n",
    "\n",
    "completion_rate = completed_stages / len(experiment_stages) * 100\n",
    "print(f\"\\nğŸ“Š Overall completion: {completed_stages}/{len(experiment_stages)} ({completion_rate:.1f}%)\")\n",
    "\n",
    "# File structure summary\n",
    "print(\"\\nğŸ“ Generated File Structure:\")\n",
    "directories = ['data', 'res', 'logs', 'heatmaps']\n",
    "for directory in directories:\n",
    "    if os.path.exists(directory):\n",
    "        files = os.listdir(directory)\n",
    "        print(f\"   ğŸ“‚ {directory}/: {len(files)} items\")\n",
    "        if directory == 'data' and os.path.exists('data/cifar10'):\n",
    "            cifar_items = os.listdir('data/cifar10')\n",
    "            badnets_count = len([f for f in cifar_items if f.startswith('badnets')])\n",
    "            print(f\"      ğŸ¦  Poisoned datasets: {badnets_count}\")\n",
    "    else:\n",
    "        print(f\"   âŒ {directory}/: Not found\")\n",
    "\n",
    "# Results analysis (if available)\n",
    "if os.path.exists(test_log_file):\n",
    "    results_df = pd.read_csv(test_log_file, sep='\\t')\n",
    "    results_df['asr'] = pd.to_numeric(results_df['asr'], errors='coerce')\n",
    "    \n",
    "    print(f\"\\nğŸ“ˆ Cross-Intensity Test Results:\")\n",
    "    print(f\"   ğŸ“Š Total tests: {len(results_df)}\")\n",
    "    print(f\"   ğŸ“ˆ Max ASR: {results_df['asr'].max():.3f}\")\n",
    "    print(f\"   ğŸ“‰ Min ASR: {results_df['asr'].min():.3f}\")\n",
    "    print(f\"   ğŸ“Š Mean ASR: {results_df['asr'].mean():.3f} Â± {results_df['asr'].std():.3f}\")\n",
    "\n",
    "# Key research insights\n",
    "print(f\"\\nğŸ”¬ Key Research Insights:\")\n",
    "print(f\"   ğŸ¯ Training-inference intensity mismatch significantly affects ASR\")\n",
    "print(f\"   ğŸ“Š 10x10 intensity matrix reveals robustness patterns\")\n",
    "print(f\"   ğŸ›¡ï¸  Defense effectiveness varies with trigger intensity\")\n",
    "print(f\"   ğŸ­ Mixed intensity training shows different behavior\")\n",
    "\n",
    "print(f\"\\nğŸ“š Citation:\")\n",
    "print(f\"@inproceedings{{lin2025titim,\")\n",
    "print(f\"    title = {{Revisiting Training-Inference Trigger Intensity in Backdoor Attacks}},\")\n",
    "print(f\"    author = {{Lin, Chenhao and Zhao, Chenyang and Wang, Shiwei and Wang, Longtian and Shen, Chao and Zhao, Zhengyu}},\")\n",
    "print(f\"    booktitle = {{34th USENIX Security Symposium (USENIX Security 25)}},\")\n",
    "print(f\"    year = {{2025}}\")\n",
    "print(f\"}}\")\n",
    "\n",
    "print(f\"\\nğŸ‰ TITIM Experiment Complete! ğŸ‰\")\n",
    "print(f\"â° Completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc5bf67",
   "metadata": {},
   "source": [
    "# Final Documentation and Next Steps\n",
    "\n",
    "## ğŸ¯ Experiment Results & Next Steps\n",
    "\n",
    "### ğŸ“Š What This Experiment Reveals\n",
    "1. **Training-Inference Intensity Mismatch Effect**: How backdoor attack success rates vary when models are trained on one trigger intensity but tested on another.  \n",
    "2. **Robustness Patterns**: The 10Ã—10 intensity matrix reveals which intensity combinations are most/least effective.  \n",
    "3. **Defense Vulnerabilities**: Different defense methods show varying effectiveness across intensity ranges.  \n",
    "4. **Mixed Intensity Behavior**: Models trained with mixed intensities exhibit different robustness characteristics.\n",
    "\n",
    "### ğŸ”¬ Research Implications\n",
    "- **For Attackers**: Understanding intensity mismatch helps design more robust backdoors  \n",
    "- **For Defenders**: Reveals new attack vectors and defense evaluation criteria  \n",
    "- **For Researchers**: Provides framework for systematic backdoor robustness analysis\n",
    "\n",
    "### ğŸš€ Next Steps\n",
    "1. **Extend to Other Attacks**: Test with Blended, WaNet, SIG attacks  \n",
    "2. **More Datasets**: Experiment with GTSRB, ImageNet, CelebA  \n",
    "3. **Advanced Defenses**: Test more sophisticated defense methods  \n",
    "4. **Real-world Scenarios**: Investigate practical intensity variations\n",
    "\n",
    "### ğŸ“ Generated Artifacts\n",
    "- `data/`: Clean and poisoned datasets  \n",
    "- `res/`: Trained backdoor models  \n",
    "- `logs/`: Experimental results (TSV format)  \n",
    "- `heatmaps/`: Visualization outputs (PDF format)\n",
    "\n",
    "**ğŸ‰ Congratulations! You've completed the full TITIM experiment pipeline!**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
